---
layout: page
comment: true
title: "Visualizing MAML with simple losses"
date: 2021-02-07
category: Reinforcement Learning
tags: [Reinforcement Learning, MAML]
disqus: jongkyu-kim
---

2021-02-07

---
> The beauty of MAML is its simplicity.
> The algorithm is very concise to be described just in a few lines.
> Attracted to the beauty, in this article, I try to visualize what the algorithm does.
> I hope it would help us get better understand of MAML.
---

### Quick review of MAML

MAML algorithm is described as below.
It runs on a nested while loop.
Inner loop calculates task losses that are updated with gradient descent. 
And all task losses sum up to make meta objective loss. 
Then outer loop optimizes meta objective loss given by inner loop. 

---
__Algorithm: Model-Agnostic Meta-Learning__ 

---
__Require:__ $p(T)$: distribution over tasks  <br>
__Require:__ $\alpha$, $\beta$: step size hyperparameters <br>
__Definition:__ $L_{T_i}(f_\theta)$: Loss for a Task, $T_i$ <br>
__Definition:__ $\sum_{T_i \sim p(T)} L_{T_i}(f_{\theta_i^{'}})$ : meta objective loss <br>
&emsp; 1: randomly initialize $\theta$ <br>
&emsp; 2: __while__ not done __do__ <br>
&emsp; 3: &emsp; Sample batch fo tasks $T_i \sim p(T)$ <br>
&emsp; 4: &emsp; __for all__ $T_i$ __do__ <br>
&emsp; 5: &emsp;&emsp; Evaluate $\nabla_\theta L_{T_i}(f_\theta)$ with respect to $K$ examples <br>
&emsp; 6: &emsp;&emsp; Compute adapted parameters with gradient decent: $\theta_i^{'} = \theta - \alpha \nabla_\theta L_{T_i}(f_\theta)$ <br>
&emsp; 7: &emsp; __end for__ <br>
&emsp; 8: &emsp; Update meta objective with gradient descent: $\theta \leftarrow \theta - \beta \nabla_\theta \sum_{T_i \sim p(T)} L_{T_i}(f_{\theta_i^{'}})$ 

---

Let me show two cases that are very simple but still valid for meta learning set-up shown above.
For each case, I will visualize task losses and the corresponding meta objective loss.

### Case 1: simple

Let's assume we have two tasks $T_0$ and $T_1$.
Then we set very simple loss functions for the two tasks as below.

$L_{T_0} = \frac{1}{2} \theta^2 \\$ <br>
$L_{T_1} = \frac{1}{2} (\theta - 1)^2$

The two equations have the same shape and the only difference is shift by 1 in $\theta$ axis.
Their visualization are as below.

<iframe
    scrolling="no"
    width="500px"
    height="500"
    src="../img/2021-02-07-MAML/figure_0.html?fullscreen=kiosk"
    frameborder="0"
    allowfullscreenbbbb></iframe>

We update the parameters, $\theta_{0}$ and $\theta_{1}$ with gradient descent using pre-defined learning rate, $\alpha$.

$$\begin{equation}
\begin{split}
\theta^{'}_{0} &= \theta - \alpha \nabla_{\theta} L_{T_0}(f_{\theta}) = \theta - \alpha \theta \\
&= (1 - \alpha) \theta\\
\theta^{'}_1 &= \theta - \alpha \nabla_{\theta} L_{T_1}(f_{\theta}) = \theta - \alpha (\theta - 1)\\
&= (1 - \alpha) \theta + \alpha
\end{split}
\end{equation}$$

We update the loss functions using the updated $\theta$ parameters.
$$ \begin{equation}
\begin{split}
L_{T_0} &= \frac{1}{2} (1-\alpha)^2\theta^2 \\
L_{T_1} &= \frac{1}{2} (1-\alpha)^2(\theta-1)^2
\end{split}
\end{equation}$$

Finally, we sum up the updated losses to get the loss for meta-objective.
Remeber that the goal of meta-learning is to find a $\theta$ that minimizes the meta-objective loss.
$$ \begin{equation}
\begin{split}
L_{M} &= \frac{1}{2} (1-\alpha)^2 \{ \theta^2 + (\theta-1)^2 \} \\
&= (1-\alpha)^2 \{ (\theta-\frac{1}{2})^2 + \frac{1}{4} \}
\end{split}
\end{equation}$$

From the equation, $\alpha$ scales the graph in $y$ axis but does not alter the scale or position in $x$ axis.
The graph of the equation given $\alpha = 0.5$ is shown below.

<iframe
    scrolling="no"
    width="500px"
    height="500"
    src="../img/2021-02-07-MAML/figure_1.html?fullscreen=kiosk"
    frameborder="0"
    allowfullscreenbbb></iframe>

Becasue we set simple task loss functions, the meta-objective loss function is also very simple. 
We easily find the optimal $\theta$ to be 0.5 even regardless of $\alpha$ in this case. 
And the optimal $\theta$ is intuitively understood because we have two loss functions of an identical shape and the middle point in $\theta$ axis is 0.5.

Just one more thing to notice is when $\alpha$ gets close to $1$ where $L_M$ becomes $0$ for any $\theta$. 
As $\alpha$ gets close to 1, gradient descent with respect to $\theta$ gets smaller and finally becomes $0$ at $alpha = 1$ over all $\theta$. 
Actually, it is the best $\alpha$ that we can choose because it makes both task losses $0$ after gradient descent update.


The process of calculation was interesting but the result turns out somewhat trivia. 
It seems like that's it for what we can get from it. 
So now we set a slightly more complicated task loss function.

### Case 2: slightly more complicated (at first)

Now we change $L_{T_0}$ from quadratic to quartic function.

$L_{T_0} = \frac{1}{4} \theta^4$ <br>$L_{T_1} = \frac{1}{2} (\theta - 1)^2$

Below are their visualization in graph.

<iframe
    scrolling="no"
    width="500px"
    height="660"
    src="../img/2021-02-07-MAML/figure_2.html?fullscreen=kiosk"
    frameborder="0"
    allowfullscreen></iframe>

We do the same steps as in case 1.
The updated parameters $\theta'_{0}$ and $\theta'_{1}$ are as below.
($\theta^{'}_1$ did not change from case 1 but was written again for easier track of calculation.)

$$\begin{equation}
\begin{split}
\theta^{'}_0  &= \theta - \alpha \nabla_{\theta} L_{T_0}(f_{\theta})\\
 &= \theta - \alpha \theta^3 \\
\theta^{'}_1  &= \theta - \alpha \nabla_{\theta} L_{T_1}(f_{\theta})\\
 &= \theta - \alpha (\theta - 1) \\
 &= (1 - \alpha) \theta + \alpha \\
\end{split}
\end{equation}$$

Then, we update the task loss functions by replacing $\theta$ with the updated $\theta'_{0}$ and $\theta'_{1}$.
$$ \begin{equation}
\begin{split}
L_{T_0} &= \frac{1}{4} (\theta - \alpha \theta^3)^4 \\
L_{T_1} &= \frac{1}{2} (1-\alpha)^2(\theta-1)^2
\end{split}
\end{equation} $$

The two updated task losses sum up to meta-objective loss as below.
The equation looks still simple but now it is hard to imagine the graph.
$$ \begin{equation}
\begin{split}
L_{M} &= \frac{1}{4} (\theta - \alpha \theta^3)^4 \\
&+ \frac{1}{2} (1-\alpha)^2(\theta-1)^2
\end{split}
\end{equation} $$

So let us visualize the equation in a graph.
This time, $\alpha$ is involved not in a simple manner.
So we need to include $\alpha$ as another axis and draw the loss not as a line but as a surface.
(In the fiture below, you can hover your mouse pointer over the surface to see graphs drawn by fixing $\theta$ or $\alpha$.)

<iframe
    scrolling="no"
    width="660px"
    height="660"
    src="../img/2021-02-07-MAML/figure_3.html?fullscreen=kiosk"
    frameborder="0"
    allowfullscreen></iframe>

Now we found the graph is not simple that it is not easy to find the optimal $\theta$ that makes the loss minimum.
In order to find the $\theta$, let us draw the gradient of meta-object loss over $\theta$ shown as below.

$\nabla_{\theta} L_{M} = (\theta - \alpha \theta^3)^3(1 - 3 \alpha \theta^2) + (1-\alpha)^2(\theta-1)$

Below is the surface visualization of the equation above. 
The intersection of the surface and the transprant plane where $z=0$ makes curvese that make the meta-objective loss minimum. 
We can see the optimal $\theta$ easier than in the previous visualization. 
And we see strong dependency of the optimal $\theta$ on $\alpha$. 

In case 2, we changed just one task loss function from $\theta^2$ to $\theta^4$. 
But we see meta-objective loss surface that is much more complicated both over $\theta$ and $\alpha$.

<iframe
    scrolling="no"
    width="660px"
    height="660"
    src="../img/2021-02-07-MAML/figure_4.html?fullscreen=kiosk"
    frameborder="0"
    allowfullscreen></iframe>

### Review

We saw what MAML actually does via simple loss functions and their visualizations. 

From the visualization, I would like to point out two things. 
First, the process and the resulting performance largely affected by task learning rate, $\alpha$. 
Second, even rather simple task loss functions can lead to complicated meta-objective function. 

I hope you enjoed it and got more concrete understanding about MAML.
